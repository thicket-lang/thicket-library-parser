/*
 * Thicket
 * https://github.com/d-plaindoux/thicket
 *
 * Copyright (c) 2015-2016 Didier Plaindoux
 * Licensed under the LGPL2 license.
 */
 
module Parser.Tokenizer

from Data.Character import char 
from Data.Sequence import Sequence
from Data.Try import try

from Parser.Token import *
from Parser.Genlex import genlex, GenlexFactory

def tokenize : genlex -> Sequence[char] -> try[Sequence[Token]] = genlex input -> {
    let factory = GenlexFactory Keyword Ident Number String Char in
        genlex generate input factory
}